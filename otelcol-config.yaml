extensions:
  health_check:
  pprof:
    endpoint: :1888
  zpages:
    endpoint: :55679

receivers:
  otlp:
    protocols:
      grpc:
      http:
  prometheus:
    config:
      scrape_configs:
        - job_name: 'sygma_relayers'
          static_configs:
            - targets: ['0.0.0.0:8888', 'localhost:9001', 'localhost:9000']
          scheme: tcp     
  hostmetrics:
    collection_interval: 10s
    scrapers:
      paging:
        metrics:
          system.paging.utilization:
            enabled: true
      load:
        cpu_average: true
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      disk:
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true
      memory:
      network:
        metrics:
          system.network.connections:
            enabled: true
      process:

processors:
  batch:
    timeout: 10s
    send_batch_max_size: 1000
    send_batch_size: 100
  resourcedetection:
    detectors: [ecs, ec2, system]

exporters:
  datadog:
    retry_on_failure:
      enabled: true
    api:
      site: 'datadoghq.com'
      key: '${{ secrets.DD_SITE }}'
    mode: distributions
  logging:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200
  prometheus:
    endpoint: 'localhost:8889'
    namespace: default
    send_timestamps: true
    metric_expiration: 180m
    enable_open_metrics: true
    resource_to_telemetry_conversion:
      enabled: true

service:
  extensions: [health_check, pprof, zpages]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [datadog, logging]
    metrics:
      receivers: [otlp, prometheus, hostmetrics]
      processors:  [batch]
      exporters: [datadog, logging, prometheus]
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, datadog]